{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI - Caribbean Challenge Competition \n",
        "\n",
        "### Train an Image Classifier from Aerial Photos with Transfer learning \n",
        "\n",
        "### CNN2d - 4layers\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        " **modify the preprocessing image.py file**\n",
        "\n",
        "- see: https://towardsdatascience.com/image-augmentation-for-deep-learning-using-keras-and-histogram-equalization-9329f6ae5085\n",
        "\n",
        "- www.github.com/rockyxu66/Kaggles_Flowers_Classification_Keras\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add skimage preprocessing techniques:\n",
        "\n",
        "- Histogram Equalization\n",
        "\n",
        "- Contrast Stretching\n",
        "\n",
        "- Adaptive Equalization"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# from sklearn.utils import class_weight\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import cv2\n",
        "from skimage import data, img_as_float\n",
        "from skimage import exposure"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TF Keras imports\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D, GlobalAveragePooling2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import *\n",
        "from keras.activations import *\n",
        "from keras.layers import *\n",
        "from keras.preprocessing import image \n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "from keras.utils import Sequence\n",
        "from keras.utils import to_categorical\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "# from tensorflow.keras import backend as K\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n",
        "sess = tf.Session(config=config)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input(x):\n",
        "    x /= 256\n",
        "    x -= 0.5\n",
        "    return x\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "#     return -dice_coef(y_true, y_pred)\n",
        "    return 1-dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "def jacard_coef_loss(y_true, y_pred):\n",
        "    return -jacard_coef(y_true, y_pred)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_id_from_path(image_path):\n",
        "    \"\"\" returns image id from image path \"\"\"\n",
        "    return image_path.split('./data/processed2/trainImages/')[0].split('.png')[0].split('-')[0][-8:]\n",
        "\n",
        "\n",
        "def get_label_from_id(image_id):\n",
        "    \"\"\" returns label from image id \"\"\"\n",
        "    return np.array(labels_org[labels_org.id==image_id].iloc[:,2:]).argmax()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load image data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "curr_path = Path('/home/ime/Documents/PycharmProjects/DrivenData/OpenAI')\n",
        "data_path = curr_path / 'data/raw'\n",
        "train_path = curr_path / 'data/pickle/'\n",
        "img_path = curr_path / 'data/processed2/trainImages/'\n",
        "\n",
        "categories = ['concrete_cement', 'healthy_metal', 'incomplete', 'irregular_metal', 'other']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all image file names\n",
        "fnames = []\n",
        "for categ in categories:\n",
        "    sub_folder = os.path.join(img_path, categ)\n",
        "    file_names = os.listdir(sub_folder)\n",
        "    full_path = [os.path.join(sub_folder, file_name) for file_name in file_names]\n",
        "    fnames.append(full_path)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print('length of each class:', [len(f) for f in fnames])\n",
        "print('total number of images:', sum([len(f) for f in fnames]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train_labels\n",
        "\n",
        "labels_org = pd.read_csv(data_path/'train_labels.csv')\n",
        "\n",
        "labels_org.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_img_id = get_image_id_from_path(fnames[3][30])\n",
        "get_label_from_id(one_img_id)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load images"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "\n",
        "for names in fnames:\n",
        "    one_class_img = [cv2.imread(name) for name in names if (cv2.imread(name)) is not None]\n",
        "    images.append(one_class_img)\n",
        "\n",
        "del one_class_img\n",
        "gc.collect()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Load images with keras\n",
        "\n",
        "# images2 = []\n",
        "# for names in fnames:\n",
        "#     one_class_img = [image.load_img(name) for name in names if (image.load_img(name)) is not None]\n",
        "#     images2.append(one_class_img)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print('no. of images for each class:', [len(f) for f in images])\n",
        "# print('no. of images for each class:', [len(f) for f in images2 if images2 is not None])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate minimal shape for all images"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(5,1, figsize=(6, 18))\n",
        "for i, imgs in enumerate(images):\n",
        "    shapes = [img.shape for img in imgs]\n",
        "    widths = [shape[0] for shape in shapes]\n",
        "    heights = [shape[1] for shape in shapes]\n",
        "    print('%d, %d is the min shape for %s' % (np.min(widths), np.min(heights), categories[i]))    \n",
        "    print()\n",
        "    print('%d, %d is the max shape for %s' % (np.max(widths), np.max(heights), categories[i]))    \n",
        "    print('-'*10)\n",
        "    ax[i].scatter(widths, heights, label=('class %s' % i))\n",
        "    ax[i].set_title(('class %s' % i))\n",
        "#     print('-'*10)\n",
        "#     ax[i].scatter(widths, heights, label=('class %s' % i))\n",
        "#     ax[i].set_title(('class %s' % i))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show sample of images for all classes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "for i, imgs in enumerate(images):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    idx = np.random.randint(len(imgs))\n",
        "    plt.imshow(imgs[idx])\n",
        "    plt.grid('off')\n",
        "    plt.title(categories[i]+' '+str(idx))\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resize all images"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_ONESIZE = True     # train with a unified image size\n",
        "# TRAIN_ONESIZE = False    # train with original image size\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "NO_CHANNELS = 3\n",
        "\n",
        "if TRAIN_ONESIZE:\n",
        "    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
        "else:\n",
        "     input_shape = (None, None, 3)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# apply to all images\n",
        "\n",
        "images_resized = []\n",
        "for i, imgs in enumerate(images):\n",
        "    images_resized.append([cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA) for img in imgs])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rand_categ = 2   # select 0-4\n",
        "\n",
        "rand_idx = np.random.randint(0, len(images[rand_categ]))\n",
        "\n",
        "print('class:', categories[rand_categ])\n",
        "print()\n",
        "print('before:', images[rand_categ][rand_idx].shape)\n",
        "print('after:', images_resized[rand_categ][rand_idx].shape)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('original image')\n",
        "plt.grid('False')\n",
        "plt.imshow(images[rand_categ][rand_idx])\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('resized image')\n",
        "plt.grid('False')\n",
        "plt.imshow(images_resized[rand_categ][rand_idx])\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Image Preprocesing Techniques"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a random resized image\n",
        "rand_idx = np.random.randint(0,1387)\n",
        "tmp_img = images_resized[0][rand_idx]\n",
        "\n",
        "# Contrast stretching\n",
        "plow, phigh = np.percentile(tmp_img, (5, 95))\n",
        "tmp_img_rescale = exposure.rescale_intensity(tmp_img, in_range=(plow, phigh))\n",
        "\n",
        "# Equalization\n",
        "tmp_img_eq = exposure.equalize_hist(tmp_img)\n",
        "\n",
        "# Adaptive Equalization\n",
        "tmp_img_adapteq = exposure.equalize_adapthist(tmp_img, clip_limit=0.03)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "fig = plt.figure(figsize=(16, 10)) \n",
        "axes = np.zeros((2, 4), dtype=np.object)\n",
        "axes[0, 0] = fig.add_subplot(2, 4, 1)\n",
        "\n",
        "# tuple to select colors of each channel line\n",
        "colors = (\"r\", \"g\", \"b\")\n",
        "channel_ids = (0, 1, 2)\n",
        "\n",
        "for i in range(1, 4):\n",
        "    axes[0, i] = fig.add_subplot(2, 4, 1+i, sharex=axes[0,0], sharey=axes[0,0])\n",
        "    \n",
        "for i in range(0, 4):\n",
        "    axes[1, i] = fig.add_subplot(2, 4, 5+i)\n",
        "\n",
        "# 1-Original low res image\n",
        "plt.subplot(2,4,1)\n",
        "plt.title('original image')\n",
        "plt.grid('False')\n",
        "plt.imshow(tmp_img)\n",
        "\n",
        "plt.subplot(2,4,5)\n",
        "plt.legend(['r', 'g', 'b'])\n",
        "plt.grid('False')\n",
        "for channel_id, c in zip(channel_ids, colors):\n",
        "        hist, bin_edges = np.histogram(tmp_img[:, :, channel_id], bins=256, range=(0, 256))\n",
        "        plt.plot(bin_edges[0:-1], hist, color=c)\n",
        "        plt.xlabel(\"Color value\")\n",
        "        plt.ylabel(\"Pixels\")\n",
        "        plt.xlim([0, 256])\n",
        "\n",
        "# 2-Contrast stretching\n",
        "plt.subplot(2,4,2)\n",
        "plt.title('Contrast stretching')\n",
        "plt.grid('False')\n",
        "plt.imshow(tmp_img_rescale)\n",
        "\n",
        "plt.subplot(2,4,6)\n",
        "plt.legend(['r', 'g', 'b'])\n",
        "plt.grid('False')\n",
        "for channel_id, c in zip(channel_ids, colors):\n",
        "        hist, bin_edges = np.histogram(tmp_img_rescale[:, :, channel_id], bins=256, range=(0, 256))\n",
        "        plt.plot(bin_edges[0:-1], hist, color=c)\n",
        "        plt.xlabel(\"Color value\")\n",
        "        plt.ylabel(\"Pixels\")\n",
        "        plt.xlim([0, 256])\n",
        "\n",
        "\n",
        "# 3-Histogram equalization\n",
        "plt.subplot(2,4,3)\n",
        "plt.title('Histogram equalization')\n",
        "plt.grid('False')\n",
        "plt.imshow(tmp_img_eq)\n",
        "\n",
        "plt.subplot(2,4,7)\n",
        "plt.legend(['r', 'g', 'b'])\n",
        "plt.grid('False')\n",
        "for channel_id, c in zip(channel_ids, colors):\n",
        "        hist, bin_edges = np.histogram(tmp_img_eq[:, :, channel_id], bins=256, range=(0, 256))\n",
        "        plt.plot(bin_edges[0:-1], hist, color=c)\n",
        "        plt.xlabel(\"Color value\")\n",
        "        plt.ylabel(\"Pixels\")\n",
        "        plt.xlim([0, 256])\n",
        "\n",
        "\n",
        "# 4-Adaptive equalization\n",
        "plt.subplot(2,4,4)\n",
        "plt.title('Adaptive equalization')\n",
        "plt.grid('False')\n",
        "plt.imshow(tmp_img_adapteq)\n",
        "\n",
        "plt.subplot(2,4,8)\n",
        "plt.legend(['r', 'g', 'b'])\n",
        "plt.grid('False')\n",
        "for channel_id, c in zip(channel_ids, colors):\n",
        "        hist, bin_edges = np.histogram(tmp_img_adapteq[:, :, channel_id], bins=256, range=(0, 256))\n",
        "        plt.plot(bin_edges[0:-1], hist, color=c)\n",
        "        plt.xlabel(\"Color value\")\n",
        "        plt.ylabel(\"Pixels\")\n",
        "        plt.xlim([0, 256])\n",
        "\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# del images, tmp_img_rescale, tmp_img, tmp_img_eq, tmp_img_adapteq\n",
        "gc.collect()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "del images_eq\n",
        "gc.collect()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply hist equalization + stretching to all resized images"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "images_eq = []\n",
        "\n",
        "for cl, imgs in enumerate(images_resized):\n",
        "    images_eq.append([exposure.rescale_intensity(img, in_range=(np.percentile(img, (5, 95))[0], np.percentile(img, (5, 95))[1])) for img in imgs])\n",
        "    \n",
        "len(images_eq)  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([len(f) for f in images_eq])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# del images_resized\n",
        "# gc.collect()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split to train/val sets"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = []\n",
        "val_images = []\n",
        "train_y = []\n",
        "val_y = []\n",
        "# for imgs in images_resized:\n",
        "for imgs in images_eq:  \n",
        "    train, val = train_test_split(imgs, test_size=0.2)\n",
        "    train_images.append(train)\n",
        "    val_images.append(val)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create labels from scratch"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# A) kernel approach\n",
        "len_train_images= [len(imgs) for imgs in train_images]\n",
        "print(len_train_images)\n",
        "print('sum of train images: ', np.sum(len_train_images))\n",
        "train_categories = np.zeros(np.sum(len_train_images), dtype='uint8')\n",
        "for i in range(5):\n",
        "    if i is 0:\n",
        "        train_categories[:len_train_images[i]] = i\n",
        "    else:\n",
        "        train_categories[np.sum(len_train_images[:i]):np.sum(len_train_images[:i+1])] = i\n",
        "\n",
        "len_val_images = [len(imgs) for imgs in val_images]\n",
        "print(len_val_images)\n",
        "print('sum of val images: ', np.sum(len_val_images))\n",
        "val_categories = np.zeros(np.sum(len_val_images), dtype='uint8')\n",
        "for i in range(5):\n",
        "    if i is 0:\n",
        "        val_categories[:len_val_images[i]] = i\n",
        "    else:\n",
        "        val_categories[np.sum(len_val_images[:i]):np.sum(len_val_images[:i+1])] = i\n",
        " \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert images to arrays"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_train_imgs = []\n",
        "tmp_val_imgs = []\n",
        "for imgs in train_images:\n",
        "    tmp_train_imgs += imgs\n",
        "    \n",
        "for imgs in val_images:\n",
        "    tmp_val_imgs += imgs\n",
        "    \n",
        "train_data = np.array(tmp_train_imgs)    \n",
        "val_data = np.array(tmp_val_imgs)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "del tmp_train_imgs, tmp_val_imgs\n",
        "gc.collect()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# tmp_train = []\n",
        "# tmp_val = []\n",
        "# for imgs in train_images:\n",
        "#     tmp_trainn = image.img_to_array(imgs)\n",
        "#     train_images2.append(tmp_train)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print('Before converting')\n",
        "print('train data:', train_data.shape)\n",
        "print('train labels:', train_categories.shape)\n",
        "# print('train labels2:', train_y.shape)\n",
        "\n",
        "train_data = train_data.astype('float32')\n",
        "val_data = val_data.astype('float32')\n",
        "\n",
        "train_labels = to_categorical(train_categories, len(categories))\n",
        "val_labels = to_categorical(val_categories, len(categories))\n",
        "\n",
        "print()\n",
        "print('After converting')\n",
        "print('train data:', train_data.shape)\n",
        "print('train labels:', train_labels.shape)\n",
        "# print('train labels2:', train_y.shape)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shuffle dataset (both features and labels using same seed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 100\n",
        "np.random.seed(SEED)\n",
        "np.random.shuffle(train_data)\n",
        "\n",
        "np.random.seed(SEED)\n",
        "np.random.shuffle(train_labels)\n",
        "\n",
        "np.random.seed(SEED)\n",
        "np.random.shuffle(val_data)\n",
        "\n",
        "np.random.seed(SEED)\n",
        "np.random.shuffle(val_labels)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# for BATCH_SIZE=128 \n",
        "# train_data = train_data[:11136]         # discard 14\n",
        "# train_labels = train_labels[:11136]\n",
        "# val_data = val_data[:3712]              # discard 8\n",
        "# val_labels = val_labels[:3712]\n",
        "print('shape of train data:', train_data.shape)\n",
        "print('shape of train labels:', train_labels.shape)\n",
        "print('shape of val data:', val_data.shape)\n",
        "print('shape of val labels:', val_labels.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Synthetic data - sampling "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# ### TODO: check with SMOTE\n",
        "# from imblearn.over_sampling import SMOTE, ADASYN\n",
        "\n",
        "# ada = SMOTE(random_state=42)\n",
        "# train_data_res, train_labels_res = ada.fit_resample(train_data, train_labels)\n",
        "# # val_data_res, val_labels_res = ada.fit_resample(val_data, val_labels)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Master params"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 200\n",
        "\n",
        "no_classes = 5"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # load weights (if internet NA)\n",
        "# WEIGHTS_PATH = curr_path/'saved_models/CNN/wheights_best.hdf5'\n",
        "\n",
        "# model = load_model(path+'model.hdf5')  \n",
        "# model.load_weights(WEIGHTS_PATH)   \n",
        "\n",
        "# str(WEIGHTS_PATH).endswith('.h5')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# WEIGHTS_PATH# Build classifier head with FC layers \n",
        "\n",
        "def build_cnn_model():\n",
        "    inp = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    \n",
        "    x = Conv2D(32, (3, 3), padding='same')(inp)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(32, (3, 3))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    \n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv2D(96, (3, 3), padding='same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(96, (3, 3), padding='same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (3, 3))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(32, (3, 3))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    \n",
        "    head = GlobalAveragePooling2D()(x)\n",
        "    head = Dropout(0.5)(head)\n",
        "#     x = Flatten()(x)\n",
        "#     x = Dense(1024)(x)\n",
        "#     x = Activation('relu')(x)\n",
        "#     x = Dropout(0.5)(x)\n",
        "    out = Dense(no_classes, activation='softmax')(head)\n",
        "\n",
        "    model = Model(inputs=[inp], outputs=[out])\n",
        "    return model\n",
        "\n",
        "\n",
        "# # Build classifier head with Avg.Pool \n",
        "\n",
        "#     out = Dense(5, activation='softmax')(head)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_cnn_model()\n",
        "# model = build_resenet_head()\n",
        "\n",
        "model.summary()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split = 142   # 105, 125, 128, 132, 142\n",
        "\n",
        "# for layer in model.layers[:split]:\n",
        "#     layer.trainable = False\n",
        "    \n",
        "    \n",
        "# for layer in model.layers[split:]:\n",
        "#     layer.trainable = True    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.set_option('display.max_rows', None)\n",
        "\n",
        "# #check trainable layers\n",
        "# layers_df = pd.DataFrame([(layer, layer.name, layer.trainable) for layer in model.layers], \n",
        "#                          columns=['Layer Type', 'Layer Name', 'Trainable'])\n",
        "\n",
        "# layers_df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile the final model after freezing weights**   "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from rectified_adam import RectifiedAdam\n",
        "from AdamW import AdamW\n",
        "\n",
        "# radam = RectifiedAdam(lr=1e-3)\n",
        "# adamw = AdamW(lr=0.001)\n",
        "\n",
        "# optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "# optimizers.RMSprop(lr=2e-5)\n",
        "# optimizers.Adam(lr=0.0001)    \n",
        "\n",
        "# metrics: 'auc',log_loss    \n",
        "\n",
        "model.compile(loss=dice_coef_loss, \n",
        "              optimizer=Adam(),                    \n",
        "              metrics=['accuracy', 'categorical_crossentropy']) \n",
        "\n",
        "# model.compile(loss='categorical_crossentropy',       \n",
        "#               optimizer=RectifiedAdam(lr=1e-3),                    \n",
        "#               metrics=['accuracy']) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# callbacks \n",
        "\n",
        "mdl_dir = '/home/ime/Documents/PycharmProjects/DrivenData/OpenAI/saved_models/model3/'      \n",
        "mdl_name = 'CNN2d_adam_dice_{epoch:02d}-{val_loss:.2f}.h5'   \n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, mode='auto') \n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4) \n",
        "mc = ModelCheckpoint(filepath=mdl_dir+mdl_name, monitor='val_loss', save_best_only=False, mode='auto')\n",
        "\n",
        "# tb = TensorBoard(log_dir=tb_dir, write_graph=True, update_freq='epoch')\n",
        "\n",
        "callback_list=[es, rlr, mc]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # class weights\n",
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# classWeight = compute_class_weight('balanced', np.unique(train_data), train_labels)   # train_categories\n",
        "# classWeight = dict(enumerate(classWeight))\n",
        "\n",
        "# files_per_class = [len(f) for f in fnames]\n",
        "# total_files = sum(files_per_class)\n",
        "# classWeight2 = {}\n",
        "# for i in range(len(files_per_class)):\n",
        "#     classWeight2[i] = 1 - (float(files_per_class[i]) / total_files)\n",
        "# #     classWeight2[i] = (float(files_per_class[i]) / total_files)\n",
        "# classWeight2"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def create_class_weight(labels_dict, mu=0.7):\n",
        "    \"\"\"\n",
        "    labels_dict : {ind_label: count_label}\n",
        "    mu : parameter to tune \n",
        "    \"\"\"\n",
        "    total = sum([len(f) for f in fnames])     # 14870\n",
        "    keys = labels_dict.keys()\n",
        "    class_weight = dict()\n",
        "\n",
        "    for key in keys:\n",
        "        score = math.log(mu*total/float(labels_dict[key]))\n",
        "        class_weight[key] = score if score > 1.0 else 1.0\n",
        "\n",
        "    return class_weight\n",
        "\n",
        "# labels_dict\n",
        "labels_dict = {0: 1387, 1: 7381, 2: 668, 3: 5241, 4: 193}\n",
        "classWeight2 = create_class_weight(labels_dict)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Generators"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # custom IDG\n",
        "# from IDG import *\n",
        "# MyImageDataGenerator\n",
        "# train_datagen = MyImageDataGenerator(\n",
        "#     rescale=1./255,\n",
        "#     contrast_stretching=True, \n",
        "#     histogram_equalization=False,\n",
        "#     adaptive_equalization=False, \n",
        "# #     rotation_range=10,\n",
        "# #     width_shift_range=0.1,\n",
        "# #     height_shift_range=0.1,\n",
        "# #     shear_range=0.2,\n",
        "# #     zoom_range=0.1,\n",
        "#     horizontal_flip=True,\n",
        "#     fill_mode='nearest'\n",
        "# )\n",
        "\n",
        "# # validation configuration: rescale only\n",
        "# val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# # Flow images \n",
        "# train_generator = train_datagen.flow(train_data, train_labels, batch_size=BATCH_SIZE)\n",
        "# val_generator = val_datagen.flow(val_data, val_labels, batch_size=BATCH_SIZE)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# train configuration: rescale, rotation, shift, shear/zoom range, horizontal flip\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# validation configuration: rescale only\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow images \n",
        "train_generator = train_datagen.flow(train_data, train_labels, batch_size=BATCH_SIZE)\n",
        "val_generator = val_datagen.flow(val_data, val_labels, batch_size=BATCH_SIZE)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show generated augmented images"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "img_id = 6203\n",
        "\n",
        "# 1208 -- class 0\n",
        "# 1205 -- class 1\n",
        "# 2500, 1200 -- class 3           \n",
        "\n",
        "img_generated = train_datagen.flow(train_data[img_id:img_id+1], train_labels[img_id:img_id+1], batch_size=1) \n",
        "img_gen = [next(img_generated) for i in range(0,5)] \n",
        "\n",
        "fig, ax = plt.subplots(1,5, figsize=(16, 6))\n",
        "print('Labels:', [np.argmax(item[1][0]) for item in img_gen]) \n",
        "l = [ax[i].imshow(img_gen[i][0][0]) for i in range(0,5)]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "\n",
        "#### Fit the model with generator"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training: ' + mdl_name)\n",
        "print()\n",
        "\n",
        "hist = model.fit_generator(\n",
        "    generator=train_generator,\n",
        "    steps_per_epoch = np.ceil(len(train_data)/BATCH_SIZE),     # 349 step*BATCH_SIZE = num of images\n",
        "    epochs=EPOCHS,\n",
        "    validation_steps=np.ceil(len(val_data)/BATCH_SIZE),        # 117 step*BATCH_SIZE = num of images\n",
        "    validation_data=val_generator,\n",
        "    verbose=1,\n",
        "    callbacks=callback_list,\n",
        "    class_weight=classWeight2,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print('Training: ' + mdl_name)\n",
        "\n",
        "# hist = model.fit_generator(\n",
        "#     generator=train_generator,\n",
        "#     steps_per_epoch = np.ceil(len(train_data)/BATCH_SIZE),     # 349 step*BATCH_SIZE = num of images\n",
        "#     epochs=EPOCHS,\n",
        "#     validation_steps=np.ceil(len(val_data)/BATCH_SIZE),        # 117 step*BATCH_SIZE = num of images\n",
        "#     validation_data=val_generator,\n",
        "#     verbose=1,\n",
        "#     callbacks=callback_list,\n",
        "#     class_weight=classWeight,\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit without generator\n",
        "train_data = train_data/255.\n",
        "val_data = val_data/255.\n",
        "\n",
        "hist2 = model.fit(train_data, train_labels, \n",
        "                  batch_size=BATCH_SIZE, \n",
        "                 epochs=EPOCHS,\n",
        "                 validation_data=(val_data, val_labels),\n",
        "                 callbacks=callback_list,\n",
        "                 class_weight=classWeight,\n",
        "                 shuffle=TTrue)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist.history['loss'], 'r')\n",
        "plt.plot(hist.history['val_loss'], 'g')\n",
        "plt.xticks()\n",
        "plt.title('loss')\n",
        "plt.legend(['train', 'val'], loc='best')    \n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(hist.history['acc'], 'r')\n",
        "plt.plot(hist.history['val_acc'], 'g')\n",
        "plt.xticks()\n",
        "plt.title('accuracy')\n",
        "plt.legend(['train', 'val'], loc='best')            \n",
        "plt.show()                "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=val_data, y=val_labels, batch_size=BATCH_SIZE) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load saved model from checkpoint"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(mdl_dir, mdl_name)\n",
        "\n",
        "model_sav = load_model(mdl_dir+mdl_name, custom_objects={'RectifiedAdam':RectifiedAdam)  #  compile=False\n",
        "\n",
        "model_sav.summary"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_sav.evaluate(x=val_data, y=val_labels, batch_size=BATCH_SIZE) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict on validation data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_val_data(val_data, model=model):\n",
        "    \"\"\"\n",
        "    Returns: pred (,5)\n",
        "             pred_class [0-4]\n",
        "             pred_prob [0. - 1.]\n",
        "    \"\"\"\n",
        "    val_input = np.reshape(val_data, (-1, IMG_SIZE, IMG_SIZE, 3))\n",
        "    val_input = val_input/255.\n",
        "    pred = model.predict(val_input)\n",
        "    pred_class = np.argmax(pred, axis=1)\n",
        "    return pred, pred_class, np.max(pred)  \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def return_categ_name(label_arr):\n",
        "    idx = np.where(label_arr == 1)\n",
        "    return idx[0][0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,20))\n",
        "for i in range(10):\n",
        "    idx = np.random.randint(len(val_data))\n",
        "\n",
        "    ax = plt.subplot(5, 2, i+1)\n",
        "    plt.imshow(val_data.astype('uint8')[idx])\n",
        "    category_idx = return_categ_name(val_labels[idx])\n",
        "\n",
        "    _, pred_class, pred_prob = predict_val_data(val_data[idx], model=model)\n",
        "    \n",
        "    plt.title('True: %s | Pred: %s %d%%' % (categories[category_idx], categories[pred_class], round(pred_prob, 2)*100))\n",
        "    plt.grid(False)\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xticklabels([])\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_val, y_pred_class_val, _ =  predict_val_data(val_data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# np.argmax(y_pred_val, axis=1)[:10], np.argmax(val_labels, axis=1)[:10]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import scikitplot as skplt\n",
        "# from scikitplot.metrics import plot_confusion_matrix\n",
        "# from matplotlib.ticker import MultipleLocator\n",
        "\n",
        "# # fig, ax  = plt.subplots(figsize=(7,7))\n",
        "# plot_confusion_matrix(np.argmax(val_labels, axis=1), np.argmax(y_pred_val, axis=1), \n",
        "#                       labels=[0,1,2,3,4],  \n",
        "#                       true_labels=[0,1,2,3,4], \n",
        "#                       pred_labels=[0,1,2,3,4],\n",
        "# #                       figsize=(10,10),\n",
        "#                       normalize=True)\n",
        "\n",
        "# # ax.xaxis.set_major_locator(MultipleLocator(1))\n",
        "# # ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "# plt.imshow(cmat)\n",
        "# plt.xticks(np.arange(len(categories)), categories, rotation=45)\n",
        "# plt.yticks(np.arange(len(categories)), categories)\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cmat = confusion_matrix(np.argmax(val_labels, axis=1), np.argmax(y_pred_val, axis=1), labels=[0,1,2,3,4])\n",
        "\n",
        "cmat   # normalize=True"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # Logloss score\n",
        "# score_logloss = log_loss(val_data, np.argmax(y_pred_val))\n",
        "# print('Score on val data:', score_logloss)\n",
        "# np.argmax(y_pred_val)\n",
        "# y_pred_val[0]\n",
        "# val_data[0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # save model (optional)\n",
        "# model.save('Resnet50-1024-512_loss_xxx.h5')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# check missclassied images\n",
        "\n",
        "def show_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n",
        "    \"\"\"\n",
        "        Print 25 examples of mislabeled images by the classifier, e.g when test_labels != pred_labels\n",
        "    \"\"\"\n",
        "    BOO = (test_labels == pred_labels)\n",
        "    mislabeled_indices = np.where(BOO == 0)\n",
        "    mislabeled_images = test_images[mislabeled_indices]\n",
        "    mislabeled_labels = pred_labels[mislabeled_indices]\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    fig.suptitle(\"Some examples of mislabeled images by the classifier:\", fontsize=16)\n",
        "    for i in range(25):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(mislabeled_images[i], cmap=plt.cm.binary)\n",
        "#         plt.xlabel(class_names[mislabeled_labels[i]])\n",
        "    plt.show()\n",
        "\n",
        "show_mislabeled_images(categories, val_data, val_labels, y_pred_class_val)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "BOO = (val_labels == y_pred_class_val)\n",
        "mislabeled_indices = np.where(BOO == 0)\n",
        "mislabeled_images = val_data[mislabeled_indices]\n",
        "mislabeled_labels = val_labels[mislabeled_indices]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val_data.shape, mislabeled_images.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "len(mislabeled_labels)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # predictions = model.predict(val_data)\n",
        "# # pred_labels = np.argmax(predictions, axis = 1)\n",
        "\n",
        "# show_mislabeled_images(categories, val_data, val_labels, y_pred_class_val)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict on Test Images"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict one Image"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_one_image(img, model=model):\n",
        "    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
        "    img = np.reshape(img, (1, IMG_SIZE, IMG_SIZE, 3))\n",
        "    img = img/255.\n",
        "    pred = model.predict(img)\n",
        "    pred_class = np.argmax(pred)\n",
        "    return pred_class, np.max(pred)    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_img = cv2.imread(test_fnames[23])\n",
        "\n",
        "# pred, prob = predict_one_image(sample_img, model)\n",
        "# print('%s %d%%' % (categories[pred], round(prob,2)*100))\n",
        "# _, ax = plt.subplots(1)\n",
        "# plt.imshow(sample_img)\n",
        "# ax.set_yticklabels([])\n",
        "# ax.set_xticklabels([])\n",
        "# plt.grid('off')\n",
        "# plt.show()\n",
        "\n",
        "# del pred, prob\n",
        "# gc.collect()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load test images filenames"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "PREDICT_WITH_GEN = True"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_fnames = []\n",
        "test_file_names = os.listdir(curr_path / 'data/processed2/testImages/')\n",
        "test_fnames = [os.path.join(curr_path / 'data/processed2/testImages/', file_name) for file_name in test_file_names]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_fnames[:1], test_file_names[:1]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# load test Images with CV2\n",
        "testImages = [cv2.imread(name) for name in test_fnames if (cv2.imread(name)) is not None]\n",
        "\n",
        "# # load test Images with Keras\n",
        "# testImages2 = [image.img_to_array(name) for name in test_fnames if (image.img_to_array(name)) is not None]\n",
        "\n",
        "len(testImages)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# check original sizes of test Images \n",
        "test_shapes = [img.shape for img in testImages]\n",
        "test_widths= [shape[0] for shape in test_shapes]\n",
        "test_heights = [shape[1] for shape in test_shapes]\n",
        "print('%d, %d is the min shape for test set' % (np.min(test_widths), np.min(test_heights)))    \n",
        "print('-'*40)\n",
        "print('%d, %d is the max shape for test set' % (np.max(test_widths), np.max(test_heights))) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resize test images"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# check size before \n",
        "print('size before:', testImages[10].shape)\n",
        "\n",
        "# resize test images\n",
        "test_images_resized = []\n",
        "test_images_resized = [cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC) for img in testImages]\n",
        "\n",
        "# check size after\n",
        "print('size after:', test_images_resized[10].shape)\n",
        "print()\n",
        "print('number of test images:', len(test_images_resized) )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# rescale \n",
        "if PREDICT_WITH_GEN == False:\n",
        "    test_images_resized = np.array(test_images_resized)/255.\n",
        "\n",
        "# reshape to 4D\n",
        "test_images_resized = np.array(test_images_resized).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# check new shape\n",
        "test_images_resized[0].shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "del testImages\n",
        "gc.collect()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference on Test Images without generator"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test predictions without generator\n",
        "test_preds = model.predict(test_images_resized, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_preds_class = np.argmax(test_preds, axis=1)\n",
        "test_preds_class2 = [categories[test_preds_class[i]] for i in range(len(test_preds))] "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference on Test images with generator"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation config for Test Images\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow(test_images_resized, batch_size=1)\n",
        "\n",
        "test_preds_gen = model.predict_generator(test_generator, verbose=1, steps=len(test_images_resized))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = np.argmax(test_preds_gen, axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds_gen[:3]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission file"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mdl_name = 'ResNet50-1024-Radam'\n",
        "out_name = 'Submission_'\n",
        "out_name += mdl_name\n",
        "out_name += '_epochs24'\n",
        "\n",
        "sub_df = pd.read_csv(data_path/'submission_format.csv')\n",
        "sub_df.head() "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df.iloc[:, 1:] = np.clip(test_preds_gen, a_min=0.05, a_max=0.95)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# export to csv \n",
        "sub_df.to_csv('%s.csv' % out_name, index=None)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tune Transfer learning ResNet-50 "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # fine tune ResNet-50 + Dense\n",
        "\n",
        "# resnet.trainable = True\n",
        "# set_trainable = False\n",
        "# for layer in resnet.layers:\n",
        "#     if layer.name in ['res5c_branch2b', 'res5c_branch2c', 'activation_97']:\n",
        "#         set_trainable = True\n",
        "#     if set_trainable:\n",
        "#         layer.trainable = True\n",
        "#     else:\n",
        "#         layer.trainable = False\n",
        "        \n",
        "# # print df        \n",
        "# layers_df = [(layer, layer.name, layer.trainable) for layer in resnet.layers]\n",
        "# layers_df = pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])\n",
        "\n",
        "# layers_df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}